"""Button-activated STT (Push-to-talk) demo.

- Hold the button (mouse down) to record.
- Release the button to stop, transcribe, and print the text.

Cross-platform (macOS/Windows) using:
- sounddevice (mic recording)
- faster-whisper (local transcription)

Install:
  pip install faster-whisper sounddevice numpy scipy

Notes:
- ì²« ì‹¤í–‰ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ ìš”ì²­í•  ìˆ˜ ìˆìŒ.
- ê¸°ë³¸ ëª¨ë¸ì€ small. ëŠë¦¬ë©´ baseë¡œ ë‚´ë¦¬ê±°ë‚˜, ë¹ ë¥´ê²Œ í•˜ë ¤ë©´ tiny.
"""

import os
import queue
import tempfile
import threading
import time
try:
    import tkinter as tk
except Exception:  # Tk ë¯¸ì„¤ì¹˜/ë¯¸ì„¤ì •(íŠ¹íˆ pyenv on macOS)
    tk = None
from dataclasses import dataclass

import numpy as np
import sounddevice as sd
from faster_whisper import WhisperModel


# =========================
# STT ì„¤ì •
# =========================
DEFAULT_MODEL_SIZE = os.getenv("WHISPER_MODEL", "tiny")  # tiny/base/small/medium
WHISPER_DEVICE = os.getenv("WHISPER_DEVICE", "auto")      # auto/cpu/cuda
WHISPER_COMPUTE = os.getenv("WHISPER_COMPUTE", "auto")   # auto/int8/float16
WHISPER_DOWNLOAD_ROOT = os.getenv(
    "WHISPER_DOWNLOAD_ROOT",
    os.path.join(os.path.dirname(__file__), ".whisper_models")
)
# ë””ì½”ë”©/ì§€ì—° íŠœë‹
BEAM_SIZE = int(os.getenv("WHISPER_BEAM", "1"))
BEST_OF = int(os.getenv("WHISPER_BEST_OF", "1"))
VAD_MIN_SILENCE_MS = int(os.getenv("VAD_MIN_SILENCE_MS", "250"))

# ì •í™•ë„ íŠœë‹ ì˜µì…˜
CONDITION_ON_PREV = os.getenv("CONDITION_ON_PREV", "0") in {"1", "true", "True"}
DECODE_TEMPERATURE = float(os.getenv("DECODE_TEMPERATURE", "0.0"))
PRINT_PRESET_HINT = os.getenv("PRINT_PRESET_HINT", "1") not in {"0", "false", "False"}

DEFAULT_DEVICE = os.getenv("AUDIO_DEVICE")  # Noneì´ë©´ ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜
SAMPLE_RATE = int(os.getenv("AUDIO_SR", "16000"))
CHANNELS = 1


@dataclass
class STTResult:
    text: str
    language: str | None = None
    seconds: float | None = None


class PushToTalkSTT:
    def __init__(self, model_size: str = DEFAULT_MODEL_SIZE):
        # faster-whisper ëª¨ë¸ ë¡œë”©(ì´ˆê¸° 1íšŒ)
        # device="auto"ë¡œ ë‘ë©´ CPU/MPS/ì¿ ë‹¤ í™˜ê²½ì— ë§ì¶° ë™ì‘
        print(
            f"[STT] Loading WhisperModel size={model_size} device={WHISPER_DEVICE} compute={WHISPER_COMPUTE} "
            f"download_root={WHISPER_DOWNLOAD_ROOT} ..."
        )
        self.model = WhisperModel(model_size, device=WHISPER_DEVICE, compute_type=WHISPER_COMPUTE, download_root=WHISPER_DOWNLOAD_ROOT)
        print("[STT] Model loaded")

        self._q: "queue.Queue[np.ndarray]" = queue.Queue()
        self._stream: sd.InputStream | None = None
        self._frames: list[np.ndarray] = []
        self._recording = False
        self._lock = threading.Lock()
        self._prev_text: str = ""  # ì´ì „ í„´ ì¸ì‹ í…ìŠ¤íŠ¸(ì„ íƒ)

    def _callback(self, indata, frames, time_info, status):
        if status:
            # statusëŠ” ë””ë²„ê¹…ìš©. í”„ë¦°íŠ¸ê°€ ì‹«ìœ¼ë©´ ì§€ì›Œë„ ë¨.
            pass
        # mono float32
        self._q.put(indata.copy())

    def start_recording(self):
        with self._lock:
            if self._recording:
                return
            self._recording = True
            self._frames = []

        # í ë¹„ìš°ê¸°
        while not self._q.empty():
            try:
                self._q.get_nowait()
            except queue.Empty:
                break

        self._stream = sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype="float32",
            device=DEFAULT_DEVICE,
            callback=self._callback,
        )
        self._stream.start()

        # í”„ë ˆì„ ìˆ˜ì§‘ ìŠ¤ë ˆë“œ
        threading.Thread(target=self._collector_loop, daemon=True).start()

    def _collector_loop(self):
        while True:
            with self._lock:
                if not self._recording:
                    break
            try:
                chunk = self._q.get(timeout=0.2)
                self._frames.append(chunk)
            except queue.Empty:
                continue

    def stop_and_transcribe(self) -> STTResult:
        with self._lock:
            if not self._recording:
                return STTResult(text="")
            self._recording = False

        # ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        if self._stream is not None:
            try:
                self._stream.stop()
                self._stream.close()
            finally:
                self._stream = None

        if not self._frames:
            return STTResult(text="")

        audio = np.concatenate(self._frames, axis=0).reshape(-1)

        # ë„ˆë¬´ ì§§ìœ¼ë©´ ì˜ë¯¸ ì—†ëŠ” ê²½ìš° ë§ìŒ
        duration = len(audio) / float(SAMPLE_RATE)
        if duration < 0.25:
            return STTResult(text="", seconds=duration)

        # faster-whisperëŠ” numpy audio(float32)ë„ ë°”ë¡œ ë°›ì„ ìˆ˜ ìˆì–´ì„œ,
        # íŒŒì¼ ì €ì¥/ì½ê¸° ì˜¤ë²„í—¤ë“œë¥¼ ì œê±°í•´ ì§€ì—°ì„ ì¤„ì¸ë‹¤.
        audio_f32 = audio.astype(np.float32)

        print(f"[STT] Transcribing... (audio={duration:.2f}s, sr={SAMPLE_RATE}, beam={BEAM_SIZE})")
        t0 = time.time()
        segments, info = self.model.transcribe(
            audio_f32,
            language="ko",
            vad_filter=True,
            vad_parameters={"min_silence_duration_ms": VAD_MIN_SILENCE_MS},
            beam_size=BEAM_SIZE,
            best_of=BEST_OF,
            temperature=DECODE_TEMPERATURE,
            condition_on_previous_text=CONDITION_ON_PREV,
            initial_prompt=(self._prev_text[-200:] if (CONDITION_ON_PREV and self._prev_text) else None),
            without_timestamps=True,
        )
        print("[STT] Transcribe finished")
        text = "".join(seg.text for seg in segments).strip()
        if CONDITION_ON_PREV and text:
            # ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ ìµœê·¼ ì¼ë¶€ë§Œ ìœ ì§€
            self._prev_text = (self._prev_text + " " + text).strip()[-400:]
        dt = time.time() - t0

        return STTResult(text=text, language=getattr(info, "language", None), seconds=dt)


def run_tk_demo():
    stt = PushToTalkSTT()

    root = tk.Tk()
    root.title("AnyGrow2 - Push-to-talk STT")
    root.geometry("520x260")

    status_var = tk.StringVar(value="ë²„íŠ¼ì„ ëˆ„ë¥´ê³  ìˆëŠ” ë™ì•ˆ ë§í•˜ì„¸ìš”. (ë–¼ë©´ ì¸ì‹)")
    out_var = tk.StringVar(value="")

    lbl_status = tk.Label(root, textvariable=status_var, wraplength=480, justify="left")
    lbl_status.pack(pady=10)

    txt_out = tk.Label(root, textvariable=out_var, wraplength=480, justify="left", font=("Arial", 12, "bold"))
    txt_out.pack(pady=10)

    def on_press(_event=None):
        out_var.set("")
        status_var.set("ğŸ™ï¸ ë“£ëŠ” ì¤‘... (ë²„íŠ¼ì„ ë–¼ë©´ ì¸ì‹í•©ë‹ˆë‹¤)")
        stt.start_recording()

    def on_release(_event=None):
        status_var.set("ğŸ§  ì¸ì‹ ì¤‘...")

        def work():
            result = stt.stop_and_transcribe()
            if result.text:
                out_var.set(result.text)
                status_var.set(f"âœ… ì¸ì‹ ì™„ë£Œ ({result.seconds:.2f}s)")
            else:
                out_var.set("")
                status_var.set("âŒ ì¸ì‹ ì‹¤íŒ¨/ë¬´ìŒ. ë‹¤ì‹œ ëˆŒëŸ¬ì„œ ë§í•´ë³´ì„¸ìš”.")

        threading.Thread(target=work, daemon=True).start()

    btn = tk.Button(root, text="ëˆ„ë¥´ê³  ë§í•˜ê¸° (Push-to-talk)", width=36, height=3)
    btn.pack(pady=10)

    # ë§ˆìš°ìŠ¤ ëˆ„ë¦„/ë–¼ê¸° ì´ë²¤íŠ¸
    btn.bind("<ButtonPress-1>", on_press)
    btn.bind("<ButtonRelease-1>", on_release)

    # í‚¤ë³´ë“œ ìŠ¤í˜ì´ìŠ¤ë„ ì§€ì› (ëˆ„ë¥´ë©´ ë…¹ìŒ, ë–¼ë©´ ì¸ì‹)
    root.bind("<KeyPress-space>", on_press)
    root.bind("<KeyRelease-space>", on_release)

    root.mainloop()


def run_cli_demo():
    """Tk ì—†ì´ë„ ë™ì‘í•˜ëŠ” ê°„ë‹¨ ë°ëª¨.

    - Enterë¥¼ ëˆ„ë¥´ë©´ ë…¹ìŒ ì‹œì‘
    - ë‹¤ì‹œ Enterë¥¼ ëˆ„ë¥´ë©´ ë…¹ìŒ ì¢…ë£Œ + ì¸ì‹
    """
    stt = PushToTalkSTT()
    print("[CLI STT] ì²« ì‹¤í–‰ì€ Whisper ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠë¼ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì¸í„°ë„· í•„ìš”)")
    print("[CLI STT] Tkinterê°€ ì—†ì–´ CLI ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    print("Enter -> ë…¹ìŒ ì‹œì‘, Enter -> ë…¹ìŒ ì¢…ë£Œ/ì¸ì‹, ì¢…ë£Œ: quit")
    if PRINT_PRESET_HINT:
        print("\n[íŒ] ì •í™•ë„ ìš°ì„  í”„ë¦¬ì…‹ ì˜ˆì‹œ:")
        print("  export WHISPER_MODEL=small")
        print("  export WHISPER_DEVICE=cpu")
        print("  export WHISPER_COMPUTE=int8")
        print("  export WHISPER_BEAM=5")
        print("  export WHISPER_BEST_OF=5")
        print("  export VAD_MIN_SILENCE_MS=500")
        print("  export CONDITION_ON_PREV=1")
        print("  python example_STT.py\n")

    while True:
        cmd = input("\n(Enter=ë…¹ìŒ ì‹œì‘, quit=ì¢…ë£Œ)> ").strip().lower()
        if cmd in {"q", "quit", "exit"}:
            break

        print("ğŸ™ï¸ ë…¹ìŒ ì¤‘... (ë‹¤ì‹œ Enterë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ/ì¸ì‹)")
        stt.start_recording()
        input()

        print("ğŸ§  ì¸ì‹ ì¤‘...")
        result = stt.stop_and_transcribe()
        if result.text:
            print(f"âœ… ì¸ì‹: {result.text}  (t={result.seconds:.2f}s)")
        else:
            print("âŒ ì¸ì‹ ì‹¤íŒ¨/ë¬´ìŒ")


if __name__ == "__main__":
    if tk is None:
        run_cli_demo()
    else:
        run_tk_demo()